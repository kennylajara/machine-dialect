# Machine Dialect (.md)

**Machine Dialect** is a programming language designed to look like natural language and feel like
structured documentation. It is written in Markdown and intended to be both human-friendly and AI-
native â€” readable by people, generatable and parsable by machines.

## Why?

Modern programming languages were made for humans to instruct machines. But now that machines can
understand and generate human-like language, itâ€™s time to rethink the language itself.

Machine Dialect is for a future where:

- **AI writes most of the code**, and humans supervise, modify, and approve.
- Code is **visually readable**, even by non-programmers.
- The structure of the program is as **intuitive as a document**, and lives comfortably inside
  Markdown files.

## Philosophy

- âœï¸ **Natural structure**: Programs are written as paragraphs, headings, lists â€” not brackets,
  semicolons, and cryptic symbols.
- ðŸ§  **AI-first**: Syntax is deterministic enough for parsing, but optimized for LLMs to generate and
  understand effortlessly.
- ðŸ‘ï¸ **Human-supervisable**: Markdown keeps everything readable, diffable, and renderable.
- ðŸª¶ **Lightweight**: No ceremony. Just write it like you'd explain it.
- ðŸ“ **Math as code**: Mathematical operations are expressed using LaTeX syntax inside `$$...$$`
  blocks. This keeps formulas readable, renderable, and easy to evaluate with symbolic math engines
  like SymPy or MathJax.
- ðŸ·ï¸ **Metadata-aware**: Executable files begin with a YAML frontmatter block (`---`) that declares
  intent (e.g. `exec: true`). This convention is widely supported by other tools and safely ignored by
  standard Markdown renderers, making it easy to difference executable files from context-only files.

## Features

- Functions are declared using Markdown headers.
- Each sentence is an instruction â€” terminated with a period.
- Markdown lists represent arrays or sets depending on.
- Key-value pairs are written like definitions: `**Label**: Value`.
- Variables, values, and calls are identified with lightweight formatting rules (e.g. **bold** for
  variables, _italics_ for constants).
- All source files are `.md` and can be opened in any Markdown editor.

## Example

```markdown
---
exec: true
---
# Shopping Calculator

## Initialize variables
Set **total** to _0_.
Set **item count** to _0_.

## Items
- Banana: _15_
- Toothpaste: _30_
- Notebook: _120_

## Compute total
Add all **Items** values to **total**.
Count all **Items**, store _them_ in **item count**.
Apply formula:

$$
\text{average} = \frac{\text{total}}{\text{itemCount}}
$$

## Results
Print: "You have spent: " + **total**.
Print: "Average per item: " + **average**.
```

## How It Works

- Markdown structure defines the hierarchy.
- The interpreter parses sentences line by line and infers instructions.
- AI models can generate this structure with very little training.
- Humans can preview and edit it using standard Markdown tools.

## Project Structure

```text
machine_dialect/
â”œâ”€â”€ machine_dialect/         # Main Python package
â”‚   â”œâ”€â”€ __main__.py          # Entry point for python -m machine_dialect
â”‚   â”œâ”€â”€ ast/                 # Abstract Syntax Tree implementation
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ ast_node.py      # Base AST node class
â”‚   â”‚   â”œâ”€â”€ expressions.py   # Expression AST nodes
â”‚   â”‚   â”œâ”€â”€ program.py       # Program AST node
â”‚   â”‚   â””â”€â”€ statements.py    # Statement AST nodes
â”‚   â”œâ”€â”€ helpers/             # Helper utilities
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ validators.py    # Validation utilities
â”‚   â”œâ”€â”€ lexer/               # Lexer implementation
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ lexer.py         # Main lexer class
â”‚   â”‚   â”œâ”€â”€ tests/           # Lexer tests
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ test_lexer.py         # Main lexer tests
â”‚   â”‚   â”‚   â””â”€â”€ test_url_literals.py  # URL literal tests
â”‚   â”‚   â””â”€â”€ tokens.py        # TokenType enum and Token class definitions
â”‚   â”œâ”€â”€ parser/              # Parser implementation
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ parser.py        # Main parser class
â”‚   â”‚   â””â”€â”€ tests/           # Parser tests
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ test_program.py         # Program parsing tests
â”‚   â”‚       â””â”€â”€ test_set_statements.py  # Set statement tests
â”‚   â””â”€â”€ repl/                # REPL implementation
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ repl.py          # Interactive REPL for tokenization
â”‚       â””â”€â”€ tests/           # REPL tests
â”‚           â”œâ”€â”€ __init__.py
â”‚           â””â”€â”€ test_repl.py
â”œâ”€â”€ machine_dialect.egg-info/  # Python package metadata
â”œâ”€â”€ md_linter/               # Rust-based Markdown linter
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ main.rs
â”‚   â”‚   â”œâ”€â”€ config.rs
â”‚   â”‚   â””â”€â”€ rules/          # Linting rules
â”‚   â”‚       â”œâ”€â”€ mod.rs
â”‚   â”‚       â””â”€â”€ md013.rs
â”‚   â”œâ”€â”€ target/              # Rust build artifacts (gitignored)
â”‚   â”œâ”€â”€ Cargo.toml
â”‚   â””â”€â”€ Cargo.lock
â”œâ”€â”€ pyproject.toml           # Python project configuration
â”œâ”€â”€ uv.lock                  # UV package manager lock file
â”œâ”€â”€ CLAUDE.md               # AI assistant guidance
â””â”€â”€ README.md               # This file
```

### Key Components

- **Lexer**: Tokenizes Machine Dialect source code into structured tokens
- **Tokens**: Defines all token types with clear prefixes (KW_for keywords, OP\_ for operators, etc.)
- **Tests**: Comprehensive test suite following Test-Driven Development (TDD)
- **MD Linter**: Ensures consistent formatting of Machine Dialect source files

## Status

> âš ï¸ This project is a prototype. We're exploring syntax design, parsing strategies, and possible
> runtimes. Expect breaking changes. Contributions welcome.

## Getting Started

### Prerequisites

- Python 3.12 or higher
- UV package manager for Python
- Rust (optional, for the Markdown linter)

### Installation

1. Clone the repository:

   ```bash
   git clone https://github.com/yourusername/machine_dialect.git
   cd machine_dialect
   ```

1. Create and activate a virtual environment:

   ```bash
   python -m venv .venv
   source .venv/bin/activate  # On Windows: .venv\Scripts\activate
   ```

1. Install dependencies:

   ```bash
   uv sync
   ```

### Running Tests

```bash
python -m pytest machine_dialect/lexer/tests/test_lexer.py -v
```

### Using the REPL

Start the interactive REPL to tokenize Machine Dialect code:

```bash
python -m machine_dialect
# or
python machine_dialect/repl/repl.py
```

Example REPL session:

```text
md> if x > 0 then return true

Tokens (7):
--------------------------------------------------
  Type                 | Literal
--------------------------------------------------
  KW_IF                | 'if'
  MISC_IDENT           | 'x'
  OP_GT                | '>'
  LIT_INT              | '0'
  KW_THEN              | 'then'
  MISC_IDENT           | 'return'
  KW_TRUE              | 'true'
--------------------------------------------------
```

## Goals

- Define a minimal, deterministic grammar.
- Build a compiler and/or interpreter in Python.
- Support a virtual machine or bytecode executor.
- Eventually: build a Rust-based interpreter for performance.
